{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# The Meteo module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meteo module handles the pre-processing of the atmoshpering forcing of the model. \n",
    "\n",
    "\n",
    "- Requires:\n",
    "\n",
    "data folder. See [README](README.md) in this folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to use the full width of the browser window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not neccessarily needed. Just to check version. Must be >= 0.6\n",
    "import pyposeidon\n",
    "pyposeidon.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyposeidon.meteo as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyposeidon.utils.pplot # initialize matplolib accessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "hv.output(widget_location='bottom')\n",
    "\n",
    "from hvplot import xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional for dark theme\n",
    "#from bokeh.themes import DARK_MINIMAL\n",
    "#hv.renderer('bokeh').theme = DARK_MINIMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional\n",
    "#pyposeidon.utils.pplot.__init__(dark_background=True) # set plt style for pplot graphics below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a folder to save the output\n",
    "import os\n",
    "if not os.path.exists('test'):\n",
    "            os.makedirs('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum information required is the geometry's extent. In the most simple case that is a lat/lon box that defines the area of interest. Without loss of generality we select below Iceland as a test case. Feel free to modify the coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define in a dictionary the properties of the model..\n",
    "geometry={'lon_min':-25., # lat/lon window\n",
    "     'lon_max':-9.,\n",
    "     'lat_min':56.,\n",
    "     'lat_max':74.,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In theory, should be enough. The default setup for the time frame attribute is the current date but this depends on the source of the atmospheric data.\n",
    "\n",
    "E.g. if the source is GFS data from an NOAA one can define the url as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime(\"today\") - pd.DateOffset(days=1) # step back one day for availability.\n",
    "r = [0, 6, 12, 18]\n",
    "h = np.argmin([n for n in [start_date.hour - x for x in r] if n > 0])\n",
    "url = \"https://nomads.ncep.noaa.gov/dods/gfs_0p25_1hr/gfs{}/gfs_0p25_1hr_{:0>2d}z\".format(\n",
    "        start_date.strftime(\"%Y%m%d\"), r[h]\n",
    "    )\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: This option would work only for small extents. For large areas (continental) use a locally stored file. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo = pt.meteo(url, **geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, atmospheric data will be available locally. More importantly, these data are provided in a forecast mode. \n",
    "\n",
    "This means that there is a sequence of files that overlap in terms of time reference as new forecasts become available. \n",
    "\n",
    "pyposeidon provides a way to merge these data in a number of ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This just a structure to create the list of paths for the actual meteo files - change appropriately \n",
    "mpaths = glob('./data/uvp*.grib')\n",
    "mpaths.sort()\n",
    "mpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {**geometry, 'meteo_source':mpaths, \n",
    "            'meteo_merge':'first', \n",
    "            'meteo_combine_by' : 'nested',\n",
    "            'meteo_xr_kwargs':{'concat_dim':'step'} } # The files are forecasting [0-72] so we combine them in terms of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve meteo forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get uvp\n",
    "meteo = pt.meteo(**dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TIP** : You can change the merging with 'meteo_merge':'last'. In this case the latter values are retained in the merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional engine options include "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### passthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_ = pt.meteo(meteo_source=meteo.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_= pt.meteo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now attach an already available Dataset. This is for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_.Dataset = meteo.Dataset\n",
    "meteo_.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the meteo Dataset is a xarray dataset all integrated viz extentions can be used to visualize the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.Dataset.msl[0,:,:].plot() # A 2D graph for one timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyposeidon provides the option to get also animation as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.Dataset.gplot.contourf(x='longitude', y='latitude',z='msl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### holoviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.Dataset.msl.hvplot.contourf(x='longitude',y='latitude',cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### geoviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoviews as gv\n",
    "import geoviews.feature as gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g50 = gf.coastline(plot=dict(scale='50m'), style=dict(linewidth=1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.Dataset.msl.hvplot(x='longitude',y='latitude',geo=True, cmap='viridis', width=800, height=400) * g50 * gf.borders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to file depending on the solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic netCDF output\n",
    "meteo.Dataset.to_netcdf('./test/test.nc') # to netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to DELFT3D format\n",
    "meteo.to_output(solver='d3d',rpath='./test/') # to u,v,p for d3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to SCHISM format\n",
    "meteo.to_output(solver='schism',rpath='./test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional options include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into more files\n",
    "meteo.to_output(solver='schism',rpath='./test/', meteo_split_by='day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define index for meteo\n",
    "meteo.to_output(solver='schism',rpath='./test/', m_index=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyPoseidon",
   "language": "python",
   "name": "pyposeidon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
